{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JeanGrant/BSRV/blob/master/CafeTech%20CNN%20Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oc0MtAd1n6bG",
        "outputId": "b9ed781d-d1cc-4fab-8941-70643fa440d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivXPrg1ItMie"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os, shutil\n",
        "\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pqaDSBvDRx6"
      },
      "outputs": [],
      "source": [
        "main_path = '/content/drive/MyDrive/CafeTech Finalized Dataset/split_80-20/'\n",
        "train_path = main_path + '/train'\n",
        "test_path = main_path + '/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzDRX-1AxtXy",
        "outputId": "5f6da7bc-311b-485f-f81f-1c776c2d1077"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "healthy: 440\n",
            "cercospora: 440\n",
            "phoma: 440\n",
            "rust: 440\n",
            "miner: 440\n"
          ]
        }
      ],
      "source": [
        "path_files = []\n",
        "path_labels = []\n",
        "for i in range(5):\n",
        "  if i == 0:\n",
        "      current_class = 'healthy'\n",
        "  elif i == 1:\n",
        "      current_class = 'cercospora'\n",
        "  elif i == 2:\n",
        "      current_class = 'phoma'\n",
        "  elif i == 3:\n",
        "      current_class = 'rust'\n",
        "  elif i == 4:\n",
        "      current_class = 'miner'\n",
        "\n",
        "  \n",
        "  #Create a list of images per classification in the original directory\n",
        "  images = sorted(os.listdir(train_path+'/'+current_class))\n",
        "  print(current_class+': '+str(len(images)))\n",
        "\n",
        "  for j in range(len(images)):\n",
        "    path_files.append(train_path+'/'+current_class+'/'+images[j])\n",
        "    path_labels.append(current_class)\n",
        "\n",
        "training_set = 'training_set.csv'\n",
        "\n",
        "df = pd.DataFrame()\n",
        "df['labels']=[str(x) for x in path_labels]\n",
        "df['images']=[str(x) for x in path_files]\n",
        "\n",
        "df.to_csv(training_set, header=True, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tohZ5d5lwvts"
      },
      "outputs": [],
      "source": [
        "# training_set = train_path+'/training_set.csv'\n",
        "train_data = pd.read_csv(training_set)\n",
        "X = train_data['images']\n",
        "Y = train_data['labels']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQnbJ3sitMii"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
        "                                   rotation_range=30,\n",
        "                                   horizontal_flip = True,\n",
        "                                   vertical_flip = True)\n",
        "validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68aTHxrUtMif",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a233a899-64cb-4ee5-f029-0befdd2578d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n",
            "87924736/87910968 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "inception = InceptionV3(input_shape=(224,224,3), weights='imagenet', include_top=False)\n",
        "for layer in inception.layers:\n",
        "  layer.trainable = False;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcIdLzPhS4pt"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "num_folds = 5\n",
        "\n",
        "checkpoint_filepath = 'inception_'\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BfPJrYzTARt"
      },
      "outputs": [],
      "source": [
        "fold_no = 1\n",
        "all_history = []\n",
        "\n",
        "for train, test in kfold.split(X,Y):\n",
        "\n",
        "  print('Fold: ' + str(fold_no))\n",
        "\n",
        "  training_data = train_data.iloc[train]\n",
        "  validation_data = train_data.iloc[test]\n",
        "\n",
        "  training_set = train_datagen.flow_from_dataframe(training_data, directory = train_path, x_col='images', y_col='labels', \n",
        "                                                   target_size = (224, 224), batch_size = 16, class_mode = 'categorical', \n",
        "                                                   shuffle=True, validate_filenames=True)\n",
        "  \n",
        "  validation_set = validation_datagen.flow_from_dataframe(validation_data, directory = train_path, x_col='images', y_col='labels', \n",
        "                                                          target_size = (224, 224), batch_size = 16, class_mode = 'categorical', \n",
        "                                                          shuffle=False, validate_filenames=True)\n",
        "\n",
        "  x = inception.output\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(256, activation='relu')(x)\n",
        "  x = Dense(128, activation='relu')(x)\n",
        "\n",
        "  predictions = Dense(5, activation='softmax')(x)\n",
        "\n",
        "  model = Model(inception.input, predictions)\n",
        "\n",
        "  keras_callbacks   = [\n",
        "        EarlyStopping(monitor='val_accuracy', patience=5, mode='max', min_delta=0.001),\n",
        "        ModelCheckpoint(filepath=checkpoint_filepath+str(fold_no)+'.h5', monitor='val_accuracy', \n",
        "                        mode='max', save_best_only=True)]\n",
        "\n",
        "  model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'],\n",
        "    optimizer =  tf.optimizers.SGD(learning_rate=0.001)\n",
        "  )\n",
        "\n",
        "  history = model.fit(\n",
        "      training_set,\n",
        "      validation_data=validation_set,\n",
        "      epochs=50,\n",
        "      batch_size=16,\n",
        "      callbacks = keras_callbacks \n",
        "    )\n",
        "  \n",
        "  all_history.append(history)\n",
        "  fold_no += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nL4WfGe7G8oM"
      },
      "outputs": [],
      "source": [
        "\n",
        "for i in range(5):\n",
        "\n",
        "  print('\\n\\n\\nMatlab Plot of Fold No: ' + str(i))\n",
        "\n",
        "  # plot the loss\n",
        "  plt.title('Fold ' + str(i+1) + ': Loss vs Epoch')\n",
        "  plt.plot(all_history[i].history['loss'], label='train loss')\n",
        "  plt.plot(all_history[i].history['val_loss'], label='val loss')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  # plot the accuracy\n",
        "  plt.title('Fold ' + str(i+1) + ': Accuracy vs Epoch')\n",
        "  plt.plot(all_history[i].history['accuracy'], label='train acc')\n",
        "  plt.plot(all_history[i].history['val_accuracy'], label='val acc')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6RvMl3vulbL"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTid8X1cWuV8"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "test_set = test_datagen.flow_from_directory(test_path,\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 20,\n",
        "                                            class_mode = 'categorical',\n",
        "                                            shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtjQWFMJj-uK"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYhrcUpyZWQu"
      },
      "outputs": [],
      "source": [
        "for i in range(5):\n",
        "  model = load_model('inception_'+str(i+1)+'.h5')\n",
        "      \n",
        "  Y_pred = model.predict(test_set)\n",
        "  y_pred = np.argmax(Y_pred, axis=1)\n",
        "      \n",
        "  print(classification_report(test_set.classes, y_pred))\n",
        "\n",
        "  data = {'y_Actual':   test_set.classes,\n",
        "            'y_Predicted':  y_pred\n",
        "            }\n",
        "\n",
        "  df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
        "  confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'], margins = True)\n",
        "\n",
        "  sn.heatmap(confusion_matrix, annot=True, fmt='g')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcTWs0uAoTut"
      },
      "source": [
        "# **Pruning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMWZskQnoLKJ",
        "outputId": "a9af9cdb-613c-43eb-c64c-902fc9448d0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |█▌                              | 10 kB 29.3 MB/s eta 0:00:01\r\u001b[K     |███                             | 20 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 30 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 40 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 51 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 61 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 71 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 81 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 92 kB 3.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 102 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 112 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 122 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 133 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 143 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 153 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 163 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 174 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 184 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 194 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 204 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 213 kB 4.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "pip install -q tensorflow-model-optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zByCW2-hoky4",
        "outputId": "718681c7-1f18-4001-9458-f38a5dfd5394"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "#load best model from KFold based on confusion matrix\n",
        "model = load_model('/tmp/tmpizfwap5z_prune_constant 0.6 60endstep_3.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zINOr9mwDaG6"
      },
      "outputs": [],
      "source": [
        "Y_pred = model.predict(test_set)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "      \n",
        "print(classification_report(test_set.classes, y_pred))\n",
        "\n",
        "data = {'y_Actual':   test_set.classes,\n",
        "            'y_Predicted':  y_pred\n",
        "            }\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
        "confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'], margins = True)\n",
        "\n",
        "sn.heatmap(confusion_matrix, annot=True, fmt='g')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIBsCACxocHO"
      },
      "outputs": [],
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "fold_no = 1\n",
        "all_history = []\n",
        "\n",
        "for train, test in kfold.split(X,Y):\n",
        "\n",
        "  model = load_model('/content/drive/MyDrive/CafeTech Finalized Dataset/split_80-20/inception_3.h5')\n",
        "\n",
        "  print('Fold: ' + str(fold_no))\n",
        "\n",
        "  training_data = train_data.iloc[train]\n",
        "  validation_data = train_data.iloc[test]\n",
        "\n",
        "  training_set = train_datagen.flow_from_dataframe(training_data, directory = train_path,\n",
        "                                                 x_col='images', y_col='labels',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 16,\n",
        "                                                 class_mode = 'categorical',\n",
        "                                                 shuffle=True, validate_filenames=True)\n",
        "  \n",
        "  validation_set = validation_datagen.flow_from_dataframe(validation_data, directory = train_path,\n",
        "                                                 x_col='images', y_col='labels',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 16,\n",
        "                                                 class_mode = 'categorical',\n",
        "                                                 shuffle=False, validate_filenames=True)\n",
        "\n",
        "  # Compute end step to finish pruning after 2 epochs.\n",
        "  batch_size = 16\n",
        "  epochs = 2\n",
        "  validation_split = 0.2\n",
        "  \n",
        "  print(len(training_set.classes))\n",
        "\n",
        "  num_images = len(training_set.classes)\n",
        "  end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "\n",
        "  targetspars = 0.6\n",
        "  beginstep_perc = 30\n",
        "  beginstep = beginstep_perc/100\n",
        "\n",
        "  new_pruning_params = {\n",
        "        'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(target_sparsity=targetspars,\n",
        "                                                   begin_step=beginstep*end_step,\n",
        "                                                   end_step=end_step\n",
        "                                                   )}\n",
        "\n",
        "  inception_model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(model, **new_pruning_params)\n",
        "\n",
        "  # Requirement for the inception_model_for_pruning\n",
        "  import tempfile\n",
        "  logdir = '/content/pruning_logs/' + str(fold_no) + '_'\n",
        "\n",
        "  callbacks = [\n",
        "    tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "    tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "  ]\n",
        "\n",
        "  inception_model_for_pruning.compile(\n",
        "      loss='categorical_crossentropy',\n",
        "      optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
        "      metrics=['accuracy'])\n",
        "\n",
        "  inception_model_for_pruning.fit(training_set,\n",
        "              validation_data = validation_set,\n",
        "              epochs = epochs,\n",
        "              callbacks=[callbacks],\n",
        "              batch_size=batch_size)\n",
        "\n",
        "  inception_model_for_export = tfmot.sparsity.keras.strip_pruning(inception_model_for_pruning)\n",
        "\n",
        "  _, inception_pruned_keras_file = tempfile.mkstemp('_prune_constant '+str(targetspars)+' '+str(beginstep_perc)+'endstep_'+str(fold_no)+'.h5')\n",
        "  tf.keras.models.save_model(inception_model_for_export, inception_pruned_keras_file, include_optimizer=False)\n",
        "  \n",
        "  all_history.append(inception_model_for_pruning)\n",
        "  fold_no += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7J4V2gPSF9g",
        "outputId": "b13d3e29-129c-4cc0-fac4-3457c07630b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "#load best model from KFold based on confusion matrix\n",
        "model = load_model('/tmp/tmpbkx4kdc9_prune_constant 0.6 30endstep_1.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "SxlAayFISF9g",
        "outputId": "d6be4c2a-01e6-4585-fbda-9b9710d7da69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.40      0.49       110\n",
            "           1       0.77      0.75      0.76       110\n",
            "           2       0.89      0.95      0.92       110\n",
            "           3       0.75      0.67      0.71       110\n",
            "           4       0.60      0.86      0.71       110\n",
            "\n",
            "    accuracy                           0.73       550\n",
            "   macro avg       0.73      0.73      0.72       550\n",
            "weighted avg       0.73      0.73      0.72       550\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "Y_pred = model.predict(test_set)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "      \n",
        "print(classification_report(test_set.classes, y_pred))\n",
        "\n",
        "data = {'y_Actual':   test_set.classes,\n",
        "            'y_Predicted':  y_pred\n",
        "            }\n",
        "\n",
        "df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
        "confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'], margins = True)\n",
        "\n",
        "sn.heatmap(confusion_matrix, annot=True, fmt='g')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soxHPActoPU_"
      },
      "source": [
        "# **Conversion and Quantization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RenKtX20dWcb"
      },
      "outputs": [],
      "source": [
        "#load best model from KFold based on confusion matrix\n",
        "model = load_model('inception_2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_m99OScZdp_T"
      },
      "outputs": [],
      "source": [
        "!mkdir \"tflite_models\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jSFOEGme9ez"
      },
      "outputs": [],
      "source": [
        "TFLITE_QUANT_MODEL = \"/content/tflite_models/inception_quant.tflite\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTjhx9TWfJVO"
      },
      "outputs": [],
      "source": [
        "run_model = tf.function(lambda x : model(x))\n",
        "\n",
        "concrete_func = run_model.get_concrete_function(\n",
        "    tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype)\n",
        ")\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converted_tflite_quant_model = converter.convert()\n",
        "open(TFLITE_QUANT_MODEL, \"wb\").write(converted_tflite_quant_model)\n",
        "\n",
        "print(\"TFLite models and their sizes:\")\n",
        "!ls \"tflite_models\" -lh"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Inception_V3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}